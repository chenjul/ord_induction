{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hit Calling for kChip Lysis-Antagonism Screen\n",
    "**Written:** 20220811\\\n",
    "**Last Updated:** 20220831"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs & Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configurable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T14:02:07.611562Z",
     "start_time": "2023-03-29T14:02:07.608180Z"
    }
   },
   "outputs": [],
   "source": [
    "file_id = 'full_batch_'\n",
    "\n",
    "# path to scripts\n",
    "script_reroute = '../path/'\n",
    "\n",
    "# total imaging tp\n",
    "num_tp = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T14:02:16.416963Z",
     "start_time": "2023-03-29T14:02:16.414302Z"
    }
   },
   "outputs": [],
   "source": [
    "# half hour tps\n",
    "exact_tp = [i/2 for i in range(num_tp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T14:02:16.133916Z",
     "start_time": "2023-03-29T14:02:16.129322Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "out_path = './output/image_analysis/'+file_id\n",
    "core_path =  './output/core/'+file_id\n",
    "cc_path =  './output/coculture/'+file_id\n",
    "\n",
    "os.makedirs('./output/', exist_ok=True)\n",
    "os.makedirs('./output/core/', exist_ok=True)\n",
    "os.makedirs('./output/coculture/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## packages & scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T14:02:19.069700Z",
     "start_time": "2023-03-29T14:02:17.168133Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import auc\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, script_reroute)\n",
    "import sytox_scripts.bootstrap_and_z as bsz\n",
    "import sytox_scripts.supplementary as helper\n",
    "import sytox_scripts.cocultures as cocultures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T14:02:19.107888Z",
     "start_time": "2023-03-29T14:02:19.100732Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting style\n",
    "plot_path = script_reroute+'sytox_scripts/plotting_parameters.py'\n",
    "%run $plot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance\n",
    "- null population = mono/mono \"self-cocultures\" as opposed to\n",
    "- experimental population = polymicrobial cocultures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## standardize scores\n",
    "- lysis score / lysis score's standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T12:18:38.965894Z",
     "start_time": "2022-11-02T12:18:38.243926Z"
    }
   },
   "outputs": [],
   "source": [
    "non_kinetic = pd.read_csv(cc_path+'summarized_cocultures_nonkinetic.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T12:18:39.479151Z",
     "start_time": "2022-11-02T12:18:39.435692Z"
    }
   },
   "outputs": [],
   "source": [
    "sig_nk = helper.standardize_dAUC_scores(non_kinetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T12:18:44.510647Z",
     "start_time": "2022-11-02T12:18:40.307110Z"
    }
   },
   "outputs": [],
   "source": [
    "sig_nk.to_csv(cc_path+'summarized_cocultures_nonkinetic_standardizeScores.csv')\n",
    "sig_nk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate p-values \n",
    "- perform a right-tailed test using standardized lysis scores and a bootstrapped (10k) null distribution \n",
    "- FDR-correct with BH procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T00:53:25.296831Z",
     "start_time": "2022-11-01T00:53:24.432315Z"
    }
   },
   "outputs": [],
   "source": [
    "sig_nk = pd.read_csv(cc_path+'summarized_cocultures_nonkinetic_standardizeScores.csv', index_col=0)\n",
    "null_nk_st = helper.get_null_pop(sig_nk)\n",
    "exp_nk_st = helper.get_exp_pop(sig_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T00:53:30.272222Z",
     "start_time": "2022-11-01T00:53:26.622608Z"
    }
   },
   "outputs": [],
   "source": [
    "null_bs = bsz.boot_array(null_nk_st.dAUC_by_SE, bs_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T00:53:37.784874Z",
     "start_time": "2022-11-01T00:53:37.135633Z"
    }
   },
   "outputs": [],
   "source": [
    "null_bs_all = np.concatenate(null_bs.values) # for distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:01:21.346342Z",
     "start_time": "2022-11-01T12:01:21.342248Z"
    }
   },
   "outputs": [],
   "source": [
    "null_bs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T00:53:45.169001Z",
     "start_time": "2022-11-01T00:53:45.162817Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_pval_bs(null_array, score, C=1):\n",
    "    ''' Right-tailed test, constant to prevent zero. '''\n",
    "    null = pd.DataFrame(null_array)\n",
    "    return (null[null[0] >= score].shape[0] + C)/null.shape[0]\n",
    "\n",
    "def get_all_pvals_bs(df, null_array, score_col='dAUC_by_SE'):\n",
    "    '''\n",
    "    Returns a df with p-values from t-distribution of null,\n",
    "    FDR-corrected p-values and neg/neg_log10 transformed p-values.\n",
    "    '''\n",
    "    df['pval'] = [calc_pval_bs(null_array, t) for t in df[score_col]]\n",
    "    df['pval_fdr'] = multipletests(df.pval, method='fdr_bh')[1]\n",
    "    df['neg_pval_fdr'] = [-p for p in df. pval_fdr]\n",
    "    df['neglog_pval'] = [-np.log(p) for p in df.pval_fdr]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:00:31.370133Z",
     "start_time": "2022-11-01T00:53:59.613253Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# or run with python script as it's a slow process\n",
    "bs_sig = get_all_pvals_bs(sig_nk, null_bs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T12:00:31.449459Z",
     "start_time": "2022-11-01T00:53:28.463Z"
    }
   },
   "outputs": [],
   "source": [
    "bs_sig.to_csv(cc_path+'summarized_cocultures_nonkinetic_w_bs_pvals.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Hit Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T19:58:36.039749Z",
     "start_time": "2022-11-04T19:57:49.292498Z"
    }
   },
   "outputs": [],
   "source": [
    "full_co_df = pd.read_csv(cc_path+'summarized_cocultures_kinetic.csv', index_col=0)\n",
    "non_kinetic = pd.read_csv(cc_path+'summarized_cocultures_nonkinetic.csv', index_col=0)\n",
    "sig_nk = pd.read_csv(cc_path+'summarized_cocultures_nonkinetic_w_bs_pvals.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## volcano plot of all conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T12:23:12.068881Z",
     "start_time": "2022-11-02T12:23:12.041639Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_volcano(df, xcol, ycol, \n",
    "                 cutoff_on=False, x_cut='', y_cut='',\n",
    "                 x_label='dAUC score', y_label='-log10(P-value)', \n",
    "                 fig_w=7, fig_h=7, save_dir=cc_path, save_desc=''):\n",
    "\n",
    "    plt.figure(figsize=(fig_w,fig_h))\n",
    "    plt.scatter(df[xcol], df[ycol], alpha=0.1, c='gray')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    \n",
    "    if cutoff_on == True:\n",
    "        plt.axhline(y=y_cut, alpha=0.1, c='red')\n",
    "        plt.axvline(x=x_cut, alpha=0.1, c='red')\n",
    "    \n",
    "    plt.savefig(save_dir+'volcano_'+save_desc+'.png')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T12:23:30.829405Z",
     "start_time": "2022-11-02T12:23:26.786332Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_volcano(sig_nk, 'dAUC_score', 'neglog_pval', save_desc='neglog_pval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply cutoffs & save .csv's of hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:46:19.619293Z",
     "start_time": "2022-11-04T20:46:19.588135Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_hit_cutoff(df, dAUC_cut, pval_cut, \n",
    "                     dAUC_col = 'dAUC_score', \n",
    "                     pval_col= 'pval_fdr'):\n",
    "    \n",
    "    return df[(df[dAUC_col] >= dAUC_cut) & (df[pval_col] <= pval_cut)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:46:26.866636Z",
     "start_time": "2022-11-04T20:46:26.857872Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call with error-adjusted empirical lysis scores \n",
    "hits_nk = apply_hit_cutoff(sig_nk, dAUC_cut=0.1, dAUC_col='dAUC_score_emp_adj', pval_cut=0.05)\n",
    "hits_nk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:47:23.364329Z",
     "start_time": "2022-11-04T20:47:23.359417Z"
    }
   },
   "outputs": [],
   "source": [
    "print(hits_nk.dAUC_score_emp_adj.max(), hits_nk.dAUC_score_emp_adj.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:47:37.876046Z",
     "start_time": "2022-11-04T20:47:37.540254Z"
    }
   },
   "outputs": [],
   "source": [
    "hits_nk.to_csv(cc_path+'summarized_hits_nonkinetic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:56:54.559481Z",
     "start_time": "2022-11-04T20:56:54.463783Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = hits_nk[['chip_ID', 'Label_left', 'Label_right', 'Left_simple', 'Right_simple', \n",
    "                     'Labels_combo', 'Combo_simple', 'full_ID']].reset_index(drop=True)\n",
    "labels_df.to_csv(cc_path+'hit_strain_labels_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:22:17.477759Z",
     "start_time": "2022-11-13T20:22:17.473899Z"
    }
   },
   "outputs": [],
   "source": [
    "def pull_final_hits_kinetic(labels_df, source_df, save_dir=cc_path, save_desc=''):\n",
    "    '''\n",
    "    Return a .csv with the full summary & calculations for all final called hits.\n",
    "    \n",
    "    Inputs:\n",
    "        labels_df/source_df: dataframes after labels have been concatenated \n",
    "    '''\n",
    "    hits_df = source_df[source_df.full_ID.isin(labels_df.full_ID)].reset_index(drop=True)\n",
    "    hits_df.to_csv(save_dir+'summarized_hits'+save_desc+'.csv')\n",
    "    \n",
    "    return hits_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T20:57:14.666629Z",
     "start_time": "2022-11-04T20:56:57.920486Z"
    }
   },
   "outputs": [],
   "source": [
    "hits_df = pull_final_hits_kinetic(labels_df, full_co_df, save_desc='_kinetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view hit curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T13:22:20.349908Z",
     "start_time": "2022-11-02T13:22:18.299307Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(cc_path+'hit_strain_labels_all.csv', index_col=0)\n",
    "hits_df = pd.read_csv(cc_path+'summarized_hits_kinetic.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:26:40.708130Z",
     "start_time": "2022-11-13T20:26:40.666883Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_all_hits(labels_df, source_df, hr_fraction=0.5, sum_col='mono_sum_RFU_adj',\n",
    "                  plots_per_page=45, plots_y=9, plots_x=5, fig_w=20, fig_h=25, \n",
    "                  rfu_lim_high=1000, rfu_lim_low=500, fold_col = 'fold_change_adj',\n",
    "                  save_dir=cc_path, filename='hit_cocultures_coplots', \n",
    "                  split_by='_', multi=False, position1=1, position2=3):\n",
    "    '''\n",
    "    NOTE: use the unfiltered file to grab all timepoints, otherwise could skip (e.g. early tp)\n",
    "    Plotted mono_sum is error-adjusted.\n",
    "    \n",
    "    Separate onto multiple pages to better view.\n",
    "    \n",
    "    On a single 20x25 page, fit 5x9 plots reasonably so divides by 45.\n",
    "    '''\n",
    "    # separate all hits across pages\n",
    "    starting_indices = list(range(0, labels_df.shape[0], plots_per_page))\n",
    "    \n",
    "    # to plot in hours\n",
    "    time_base = source_df.tp.unique()\n",
    "    times = [t*hr_fraction for t in time_base] \n",
    "    \n",
    "    # save all to master PDF\n",
    "    with PdfPages(save_dir+filename+'.pdf') as pdf:\n",
    "\n",
    "        # plot each coculture\n",
    "        for ind in starting_indices:\n",
    "            # RFUs per page\n",
    "            fig = plt.figure(figsize=(fig_w, fig_h))\n",
    "            fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "            \n",
    "            fig2 = plt.figure(figsize=(fig_w, fig_h))\n",
    "            fig2.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "            # respective fold-changes on next page\n",
    "            fig3 = plt.figure(figsize=(fig_w, fig_h))\n",
    "            fig3.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "            for i, n in enumerate(labels_df.iloc[ind:ind+plots_per_page].index):\n",
    "                # pull all data for single coculture\n",
    "                \n",
    "                # chip_ID enabled for batch\n",
    "                chip_df = source_df[source_df.chip_ID.str.contains(labels_df.chip_ID[n])]\n",
    "                \n",
    "                sub_df = helper.extract_combos(chip_df, labels_df.Label_left[n],\n",
    "                                               labels_df.Label_right[n])\n",
    "                \n",
    "                # for cleaner title\n",
    "                trimmed_left = helper.trim_label_name(labels_df.Label_left[n], multi=True, \n",
    "                                                      position1=position1, position2=position2)\n",
    "                trimmed_right = helper.trim_label_name(labels_df.Label_right[n], multi=True, \n",
    "                                                       position1=position1, position2=position2)\n",
    "                combo = trimmed_left + '/' + trimmed_right + '(%s)' %labels_df.chip_ID[n]\n",
    "\n",
    "                # coplot RFUs - high lim\n",
    "                ax = fig.add_subplot(plots_y, plots_x, i+1)\n",
    "                ax.errorbar(times, y=sub_df.co_RFU, yerr=sub_df.co_error, alpha=0.5)\n",
    "                ax.errorbar(times, y=sub_df[sum_col], yerr=sub_df.mono_sum_error, alpha=0.5)\n",
    "                ax.errorbar(times, y=sub_df.left_RFU, yerr=sub_df.left_error, alpha=0.5)\n",
    "                ax.errorbar(times, y=sub_df.right_RFU, yerr=sub_df.right_error, alpha=0.5)\n",
    "                ax.set_ylim(0, rfu_lim_high)\n",
    "                ax.set_title(combo)\n",
    "                \n",
    "                # coplot RFUs - low lim\n",
    "                ax2 = fig2.add_subplot(plots_y, plots_x, i+1)\n",
    "                ax2.errorbar(times, y=sub_df.co_RFU, yerr=sub_df.co_error, alpha=0.5)\n",
    "                ax2.errorbar(times, y=sub_df[sum_col], yerr=sub_df.mono_sum_error, alpha=0.5)\n",
    "                ax2.errorbar(times, y=sub_df.left_RFU, yerr=sub_df.left_error, alpha=0.5)\n",
    "                ax2.errorbar(times, y=sub_df.right_RFU, yerr=sub_df.right_error, alpha=0.5)\n",
    "                ax2.set_ylim(0, rfu_lim_low)\n",
    "                ax2.set_title(combo)\n",
    "\n",
    "                # fold-changes on next page \n",
    "                ax3 = fig3.add_subplot(plots_y, plots_x, i+1)\n",
    "                ax3.plot(times, sub_df[fold_col])\n",
    "                ax3.set_title(combo)\n",
    "\n",
    "            fig.legend(['coculture', 'mono sum', 'left', 'right'], loc='right')\n",
    "            fig2.legend(['coculture', 'mono sum', 'left', 'right'], loc='right')\n",
    "            fig3.legend(['experimental/expected'], loc='right')\n",
    "            \n",
    "            fig.text(0.5, 0.08, 'time (h)', ha='center', fontsize=20)\n",
    "            fig.text(0.08, 0.5,'RFU', va='center', rotation='vertical', fontsize=20)\n",
    "            fig2.text(0.5, 0.08, 'time (h)', ha='center', fontsize=20)\n",
    "            fig2.text(0.08, 0.5,'RFU', va='center', rotation='vertical', fontsize=20)\n",
    "            fig3.text(0.5, 0.08, 'time (h)', ha='center', fontsize=20)\n",
    "            fig3.text(0.08, 0.5, 'fold-change (experimental/expected)', va='center', rotation='vertical', fontsize=20)\n",
    "\n",
    "            pdf.savefig(fig)\n",
    "            pdf.savefig(fig2)\n",
    "            pdf.savefig(fig3)\n",
    "            \n",
    "        plt.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T14:34:34.616512Z",
     "start_time": "2022-11-02T14:34:34.055681Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort to group same type of combination (labels) \n",
    "labels_sorted = labels_df.sort_values(by=['Left_simple', 'Right_simple', 'Label_left', 'Label_right', 'chip_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-02T15:53:31.835343Z",
     "start_time": "2022-11-02T14:35:22.804832Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_all_hits(labels_sorted, hits_df, rfu_lim_high=3000, filename='hit_cocultures_coplots_sorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chip Overlap Hit Calling\n",
    "- final hit must be found on at least two chips (inocula/ratio-level considered separately; i.e. not simplified labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:21:47.132531Z",
     "start_time": "2022-11-13T20:21:45.356577Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(cc_path+'hit_strain_labels_all.csv', index_col=0)\n",
    "hits_df = pd.read_csv(cc_path+'summarized_hits_kinetic.csv', index_col=0)\n",
    "hits_nk = pd.read_csv(cc_path+'summarized_hits_nonkinetic.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:21:51.375385Z",
     "start_time": "2022-11-13T20:21:51.356922Z"
    }
   },
   "outputs": [],
   "source": [
    "hits_nk = hits_nk.sort_values(by=['Left_simple', 'Right_simple', 'Label_left', 'Label_right', 'chip_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## condition must appear on two chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:22:04.593849Z",
     "start_time": "2022-11-13T20:22:04.565713Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap = hits_nk[hits_nk.groupby('Labels_combo')['Labels_combo'].transform('size').gt(1)] # greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:22:04.733376Z",
     "start_time": "2022-11-13T20:22:04.722850Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:22:06.693384Z",
     "start_time": "2022-11-13T20:22:06.513664Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap.to_csv(cc_path+'summarized_hits_nonkinetic_chipOverlap.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:24:15.423322Z",
     "start_time": "2022-11-13T20:24:15.365416Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_overlap = overlap[['chip_ID', 'Label_left', 'Label_right', 'Left_simple', 'Right_simple', \n",
    "                          'Labels_combo', 'Combo_simple', 'full_ID']].reset_index(drop=True)\n",
    "\n",
    "# sort to group same type of combination \n",
    "overlap_sorted = labels_overlap.sort_values(by=['Left_simple', 'Right_simple', 'Label_left', 'Label_right', 'chip_ID'])\n",
    "overlap_sorted.to_csv(cc_path+'hit_strain_labels_overlap_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T20:22:29.388324Z",
     "start_time": "2022-11-13T20:22:21.438838Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap_kinetic = pull_final_hits_kinetic(overlap, hits_df, save_desc='_kinetic_chipOverlap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot final hits\n",
    "- meets lysis score & adjusted-pvalue threshold\n",
    "- found on at least 2 kChips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-13T21:11:26.472027Z",
     "start_time": "2022-11-13T20:26:45.304183Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_all_hits(labels_overlap, overlap_kinetic, rfu_lim_high=3000, filename='hit_cocultures_coplots_sorted_overlap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Scores Per Unique Coculture\n",
    "**2 methods to track best conditions per coculture** \n",
    "- highest score among all biological replicates & ratios (\"max\")\n",
    "- mean of all scores which passed, error-adjusted (\"best\")\n",
    "\n",
    "Produces dataframe with best scores, ranked scores, and associated inocula ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T21:54:38.459808Z",
     "start_time": "2022-11-04T21:54:37.297710Z"
    }
   },
   "outputs": [],
   "source": [
    "overlap_nk = pd.read_csv(cc_path+'summarized_hits_nonkinetic_chipOverlap.csv', index_col=0)\n",
    "overlap_kinetic = pd.read_csv(cc_path+'summarized_hits_kinetic_chipOverlap.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call most robust score among inocula ratios per hit conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T21:55:12.385093Z",
     "start_time": "2022-11-04T21:55:12.371212Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_robust_hit(df, score_col='dAUC_score_emp_adj'):\n",
    "    ''' \n",
    "    Method 1: absolute max of all scores\n",
    "    Method 2: mean score from all passing conditions, error-adjusted by the std of all passing scores\n",
    "    '''\n",
    "    all_subdfs = []\n",
    "    \n",
    "    for combo in df.Combo_simple.unique():\n",
    "        subdf = df[df.Combo_simple.str.contains(combo)].reset_index(drop=True)\n",
    "        \n",
    "        # method 2 -- error-adjusted mean, \"best\" score\n",
    "        sub_mean = subdf.groupby(['Labels_combo']).mean()[score_col]\n",
    "        sub_std = subdf.groupby(['Labels_combo']).std()[score_col]\n",
    "        sub_adj = sub_mean - sub_std \n",
    "        \n",
    "        calc_df = pd.DataFrame([sub_adj, sub_mean, sub_std], ['adjusted_score','mean', 'std']).T\n",
    "        calc_df['ratio'] = [('_').join(i.split('_')[2::3]) for i in calc_df.index]\n",
    "        calc_df = calc_df.sort_values('adjusted_score', ascending=False)\n",
    "        \n",
    "        hh = calc_df[calc_df.ratio.str.contains('high_high')][['adjusted_score','mean','std']].rename(columns={'adjusted_score': 'hh_adj', 'mean': 'hh_mean', 'std':'hh_std'}).reset_index(drop=True)\n",
    "        hl = calc_df[calc_df.ratio.str.contains('high_low')][['adjusted_score','mean','std']].rename(columns={'adjusted_score': 'hl_adj', 'mean': 'hl_mean', 'std':'hl_std'}).reset_index(drop=True)\n",
    "        lh = calc_df[calc_df.ratio.str.contains('low_high')][['adjusted_score','mean','std']].rename(columns={'adjusted_score': 'lh_adj', 'mean': 'lh_mean', 'std':'lh_std'}).reset_index(drop=True)\n",
    "        ll = calc_df[calc_df.ratio.str.contains('low_low')][['adjusted_score','mean','std']].rename(columns={'adjusted_score': 'll_adj', 'mean': 'll_mean', 'std':'ll_std'}).reset_index(drop=True)\n",
    "        \n",
    "        # method 1 -- max score\n",
    "        max_score = subdf[score_col].max()\n",
    "        max_ID = subdf.full_ID[subdf[score_col].idxmax(axis=0)]\n",
    "        max_ratio = ('_').join(max_ID.split('_')[3::3])\n",
    "        \n",
    "        # some ratios may be empty -- to prevent df join from failing\n",
    "        full = pd.DataFrame({'Combo_simple': [combo], \n",
    "                             'Left_simple': [combo.split('_')[0]], 'Right_simple': [combo.split('_')[1]],\n",
    "                             'best_ratio': [calc_df.ratio[0]], 'best_score': [calc_df.adjusted_score[0]],\n",
    "                             'ratio_ranking': [list(calc_df.ratio)], 'score_ranking': [list(calc_df.adjusted_score)],\n",
    "                             'max_score': [max_score], 'max_ID': max_ID, 'max_ratio': [max_ratio]})\n",
    "        \n",
    "        full['ratio_match'] = [True if max_ratio == calc_df.ratio[0] else False]\n",
    "        \n",
    "        full = full.join([hh,hl,lh,ll])\n",
    "        all_subdfs.append(full)\n",
    "\n",
    "    return pd.concat(all_subdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T21:55:19.078568Z",
     "start_time": "2022-11-04T21:55:12.824562Z"
    }
   },
   "outputs": [],
   "source": [
    "robust_scores = call_robust_hit(overlap_nk)\n",
    "robust_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T21:55:19.643225Z",
     "start_time": "2022-11-04T21:55:19.602693Z"
    }
   },
   "outputs": [],
   "source": [
    "robust_scores.to_csv(cc_path+'summarized_ranked_scores_per_coculture.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-04T21:55:20.202510Z",
     "start_time": "2022-11-04T21:55:20.169443Z"
    }
   },
   "outputs": [],
   "source": [
    "# can load & maintain lists\n",
    "robust_scores.to_pickle(cc_path+'summarized_ranked_scores_per_coculture.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
